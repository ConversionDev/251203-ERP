"""
Customer Service - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
B2B ERP ê³ ê° ë°ì´í„° ë¶„ì„ ë° ML ì„œë¹„ìŠ¤
"""
import csv
from pathlib import Path
from typing import List, Optional, Dict, Any

# ë°ì´í„° ë¶„ì„ ë° ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd
import numpy as np

# Scikit-learn ëª¨ë“ˆë“¤
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# HuggingFace Datasets
from datasets import Dataset, DatasetDict

# ë””ë²„ê¹… ë„êµ¬
from icecream import ic

# ë‚´ë¶€ ëª¨ë“ˆ
from app.customer.customer_model import (
    CustomerDetail, CustomerSimple, CustomerStatistics,
    IndustryStatistics, ChurnPrediction, CustomerModel
)


class CustomerService:
    """ê³ ê° ë°ì´í„° ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.csv_path = Path(__file__).parent / "customer_data.csv"
        self.df: Optional[pd.DataFrame] = None
        self.model = CustomerModel()
        ic(f"ğŸ“ CSV ê²½ë¡œ: {self.csv_path}")
    
    def load_data(self) -> pd.DataFrame:
        """CSV ë°ì´í„° ë¡œë“œ"""
        if self.df is None:
            ic("ğŸ“‚ ê³ ê° ë°ì´í„° ë¡œë”© ì¤‘...")
            self.df = pd.read_csv(self.csv_path)
            ic(f"âœ… {len(self.df)}ê°œ ê³ ê° ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return self.df
    
    # ========================================================================
    # 1. ê³ ê° ë°ì´í„° ì¡°íšŒ (CRUD)
    # ========================================================================
    
    def get_all_customers(self, limit: Optional[int] = None) -> List[CustomerDetail]:
        """ì „ì²´ ê³ ê° ì¡°íšŒ"""
        df = self.load_data()
        
        if limit:
            df = df.head(limit)
        
        customers = []
        for _, row in df.iterrows():
            customer = CustomerDetail(**row.to_dict())
            customers.append(customer)
        
        ic(f"ğŸ“‹ {len(customers)}ê°œ ê³ ê° ì¡°íšŒ")
        return customers
    
    def get_customers_simple(self, limit: Optional[int] = None) -> List[CustomerSimple]:
        """ê³ ê° ê°„ë‹¨ ì •ë³´ ì¡°íšŒ (í™”ë©´ í‘œì‹œìš©)"""
        df = self.load_data()
        
        if limit:
            df = df.head(limit)
        
        customers = []
        for _, row in df.iterrows():
            customer = CustomerSimple(
                customer_id=row['customer_id'],
                company_name=row['company_name'],
                status=row['status'],
                total_orders=row['total_orders'],
                total_revenue=row['total_revenue'],
                churn_risk="ìœ„í—˜" if row['churn_risk'] == 1 else "ì•ˆì „"
            )
            customers.append(customer)
        
        return customers
    
    def get_customer_by_id(self, customer_id: str) -> Optional[CustomerDetail]:
        """ê³ ê° IDë¡œ ì¡°íšŒ"""
        df = self.load_data()
        customer_df = df[df['customer_id'] == customer_id]
        
        if customer_df.empty:
            ic(f"âŒ ê³ ê° {customer_id} ì—†ìŒ")
            return None
        
        customer = CustomerDetail(**customer_df.iloc[0].to_dict())
        ic(f"âœ… ê³ ê° {customer_id} ì¡°íšŒ ì™„ë£Œ")
        return customer
    
    def filter_by_status(self, status: str) -> List[CustomerDetail]:
        """ìƒíƒœë³„ í•„í„°ë§ (í™œì„±/ë¹„í™œì„±)"""
        df = self.load_data()
        filtered_df = df[df['status'] == status]
        
        customers = []
        for _, row in filtered_df.iterrows():
            customers.append(CustomerDetail(**row.to_dict()))
        
        ic(f"ğŸ“Š ìƒíƒœ={status}: {len(customers)}ê°œ")
        return customers
    
    def filter_by_industry(self, industry: str) -> List[CustomerDetail]:
        """ì—…ì¢…ë³„ í•„í„°ë§"""
        df = self.load_data()
        filtered_df = df[df['industry'] == industry]
        
        customers = []
        for _, row in filtered_df.iterrows():
            customers.append(CustomerDetail(**row.to_dict()))
        
        ic(f"ğŸ“Š ì—…ì¢…={industry}: {len(customers)}ê°œ")
        return customers
    
    def filter_by_churn_risk(self, risk: int) -> List[CustomerDetail]:
        """ì´íƒˆ ìœ„í—˜ë„ë³„ í•„í„°ë§ (0=ì•ˆì „, 1=ìœ„í—˜)"""
        df = self.load_data()
        filtered_df = df[df['churn_risk'] == risk]
        
        customers = []
        for _, row in filtered_df.iterrows():
            customers.append(CustomerDetail(**row.to_dict()))
        
        risk_label = "ìœ„í—˜" if risk == 1 else "ì•ˆì „"
        ic(f"ğŸ“Š ì´íƒˆ ìœ„í—˜={risk_label}: {len(customers)}ê°œ")
        return customers
    
    # ========================================================================
    # 2. í†µê³„ ë¶„ì„
    # ========================================================================
    
    def get_statistics(self) -> CustomerStatistics:
        """ì „ì²´ ê³ ê° í†µê³„"""
        df = self.load_data()
        
        stats = CustomerStatistics(
            total_customers=len(df),
            active_customers=len(df[df['status'] == 'í™œì„±']),
            inactive_customers=len(df[df['status'] == 'ë¹„í™œì„±']),
            high_risk_customers=len(df[df['churn_risk'] == 1]),
            total_revenue=int(df['total_revenue'].sum()),
            avg_revenue_per_customer=float(df['total_revenue'].mean()),
            avg_orders_per_customer=float(df['total_orders'].mean())
        )
        
        ic("ğŸ“Š í†µê³„ ê³„ì‚° ì™„ë£Œ")
        return stats
    
    def get_industry_statistics(self) -> List[IndustryStatistics]:
        """ì—…ì¢…ë³„ í†µê³„"""
        df = self.load_data()
        
        industry_stats = []
        for industry in df['industry'].unique():
            industry_df = df[df['industry'] == industry]
            
            stat = IndustryStatistics(
                industry=industry,
                customer_count=len(industry_df),
                total_revenue=int(industry_df['total_revenue'].sum()),
                avg_revenue=float(industry_df['total_revenue'].mean()),
                churn_rate=float(industry_df['churn_risk'].mean() * 100)
            )
            industry_stats.append(stat)
        
        # ë§¤ì¶œ ìˆœìœ¼ë¡œ ì •ë ¬
        industry_stats.sort(key=lambda x: x.total_revenue, reverse=True)
        
        ic(f"ğŸ“Š {len(industry_stats)}ê°œ ì—…ì¢… í†µê³„ ì™„ë£Œ")
        return industry_stats
    
    def get_top_customers(self, limit: int = 10, by: str = "revenue") -> List[CustomerDetail]:
        """ìƒìœ„ ê³ ê° ì¡°íšŒ"""
        df = self.load_data()
        
        if by == "revenue":
            sorted_df = df.sort_values('total_revenue', ascending=False)
        elif by == "orders":
            sorted_df = df.sort_values('total_orders', ascending=False)
        else:
            sorted_df = df
        
        top_df = sorted_df.head(limit)
        
        customers = []
        for _, row in top_df.iterrows():
            customers.append(CustomerDetail(**row.to_dict()))
        
        ic(f"ğŸ† ìƒìœ„ {limit}ê°œ ê³ ê° ì¡°íšŒ (ê¸°ì¤€: {by})")
        return customers
    
    # ========================================================================
    # 3. ML ì „ì²˜ë¦¬ ë° ë¶„ì„
    # ========================================================================
    
    def preprocess(self) -> Dict[str, Any]:
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        ic("ğŸ”§ ì „ì²˜ë¦¬ ì‹œì‘")
        df = self.load_data()
        
        # ê²°ì¸¡ì¹˜ í™•ì¸
        missing_values = df.isnull().sum()
        
        # ìˆ˜ì¹˜í˜• íŠ¹ì„±
        numeric_features = [
            'total_orders', 'total_revenue', 'avg_order_value',
            'last_order_days', 'contract_months', 'employee_count',
            'overdue_count', 'response_time_hours', 'meeting_count',
            'support_tickets', 'annual_growth_rate'
        ]
        
        # ë²”ì£¼í˜• íŠ¹ì„±
        categorical_features = ['company_type', 'industry', 'region', 'payment_terms']
        
        ic("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ")
        
        return {
            "total_rows": len(df),
            "numeric_features": numeric_features,
            "categorical_features": categorical_features,
            "missing_values": missing_values.to_dict(),
            "target": "churn_risk"
        }
    
    def split_data(self, test_size: float = 0.2) -> Dict[str, Any]:
        """í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• """
        ic("âœ‚ï¸ ë°ì´í„° ë¶„í•  ì‹œì‘")
        df = self.load_data()
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_columns = [
            'total_orders', 'total_revenue', 'avg_order_value',
            'last_order_days', 'contract_months', 'employee_count',
            'overdue_count', 'response_time_hours', 'meeting_count',
            'support_tickets', 'annual_growth_rate'
        ]
        
        X = df[feature_columns]
        y = df['churn_risk']
        
        # ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        ic(f"âœ… í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")
        
        return {
            "train_size": len(X_train),
            "test_size": len(X_test),
            "train_churn_rate": float(y_train.mean()),
            "test_churn_rate": float(y_test.mean()),
            "features": feature_columns
        }
    
    # ========================================================================
    # 4. ML ëª¨ë¸ë§ ë° ì˜ˆì¸¡
    # ========================================================================
    
    def train_model(self) -> Dict[str, Any]:
        """ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ"""
        ic("ğŸ¤– ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        df = self.load_data()
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        feature_columns = [
            'total_orders', 'total_revenue', 'avg_order_value',
            'last_order_days', 'contract_months', 'employee_count',
            'overdue_count', 'response_time_hours', 'meeting_count',
            'support_tickets', 'annual_growth_rate'
        ]
        
        X = df[feature_columns]
        y = df['churn_risk']
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # ëª¨ë¸ í•™ìŠµ (Random Forest)
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        # íŠ¹ì„± ì¤‘ìš”ë„
        feature_importance = dict(zip(feature_columns, model.feature_importances_))
        sorted_importance = dict(sorted(feature_importance.items(), key=lambda x: x[1], reverse=True))
        
        ic(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (ì •í™•ë„: {accuracy:.2%})")
        
        return {
            "model_type": "RandomForestClassifier",
            "accuracy": float(accuracy),
            "train_size": len(X_train),
            "test_size": len(X_test),
            "feature_importance": sorted_importance
        }
    
    def predict_churn(self, customer_id: str) -> ChurnPrediction:
        """ê³ ê° ì´íƒˆ í™•ë¥  ì˜ˆì¸¡"""
        customer = self.get_customer_by_id(customer_id)
        
        if not customer:
            raise ValueError(f"ê³ ê° {customer_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê³ ê° ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        customer_data = customer.model_dump()
        
        # ì´íƒˆ í™•ë¥  ì˜ˆì¸¡
        churn_prob = self.model.predict_churn(customer_data)
        risk_level = self.model.get_risk_level(churn_prob)
        key_factors = self.model.get_key_factors(customer_data)
        recommendations = self.model.get_recommendations(risk_level, key_factors)
        
        prediction = ChurnPrediction(
            customer_id=customer_id,
            company_name=customer.company_name,
            churn_probability=churn_prob,
            risk_level=risk_level,
            key_factors=key_factors,
            recommendations=recommendations
        )
        
        ic(f"ğŸ¯ {customer_id} ì´íƒˆ í™•ë¥ : {churn_prob:.2%} ({risk_level})")
        return prediction
    
    # ========================================================================
    # 5. HuggingFace Datasets
    # ========================================================================
    
    def to_huggingface_dataset(self) -> Dataset:
        """HuggingFace Datasetìœ¼ë¡œ ë³€í™˜"""
        ic("ğŸ¤— HuggingFace Dataset ìƒì„± ì¤‘...")
        df = self.load_data()
        
        dataset = Dataset.from_pandas(df)
        ic(f"âœ… Dataset ìƒì„± ì™„ë£Œ: {len(dataset)}ê°œ ìƒ˜í”Œ")
        
        return dataset
    
    def to_huggingface_datasetdict(self, test_size: float = 0.2) -> DatasetDict:
        """HuggingFace DatasetDictìœ¼ë¡œ ë³€í™˜ (train/test ë¶„í• )"""
        ic("ğŸ¤— HuggingFace DatasetDict ìƒì„± ì¤‘...")
        df = self.load_data()
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        train_df, test_df = train_test_split(
            df, test_size=test_size, random_state=42, stratify=df['churn_risk']
        )
        
        dataset_dict = DatasetDict({
            'train': Dataset.from_pandas(train_df.reset_index(drop=True)),
            'test': Dataset.from_pandas(test_df.reset_index(drop=True))
        })
        
        ic(f"âœ… DatasetDict ìƒì„± ì™„ë£Œ: train={len(dataset_dict['train'])}, test={len(dataset_dict['test'])}")
        
        return dataset_dict

