"""
Titanic Service - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
"""
from typing import Dict, Any, List, Optional

# ë””ë²„ê¹… ë„êµ¬ (icecream>=2.1.3)
from icecream import ic

# ë‚´ë¶€ ëª¨ë“ˆ
from app.titanic.titanic_method import TitanicMethod
from app.titanic.titanic_model import TitanicPassenger, TitanicPassengerList, TitanicPassengerSimple
from app.titanic.titanic_dataset import TitanicDataset

# TODO: í–¥í›„ ì‚¬ìš© ì˜ˆì • (ë‹¤ë¥¸ ë©”ì„œë“œì—ì„œ ì‚¬ìš©)
import pandas as pd  # pandas>=2.1.0
import numpy as np  # numpy>=1.24.0
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
# from sklearn.preprocessing import StandardScaler, OneHotEncoder
# from sklearn.compose import ColumnTransformer
# from sklearn.impute import SimpleImputer
# from sklearn.pipeline import Pipeline
# from datasets import Dataset, DatasetDict


class TitanicService:
    """íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ ë©”ì„œë“œë¥¼ ìœ„í•œ ì´ˆê¸°í™”
        self.train_csv_path = Path(__file__).parent / "train.csv"
        self.test_csv_path = Path(__file__).parent / "test.csv"
        self.train_df: Optional[pd.DataFrame] = None
        self.test_df: Optional[pd.DataFrame] = None
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë° ëª¨ë¸ ì €ì¥
        self.processed_dataset: Optional[TitanicDataset] = None
        self.train_labels: Optional[pd.DataFrame] = None
        self.models: Dict[str, Any] = {}
        self.X_train: Optional[pd.DataFrame] = None
        self.X_test: Optional[pd.DataFrame] = None
        self.y_train: Optional[pd.Series] = None
        self.y_test: Optional[pd.Series] = None
        
        ic(f"ğŸ“ Train CSV ê²½ë¡œ: {self.train_csv_path}")
        ic(f"ğŸ“ Test CSV ê²½ë¡œ: {self.test_csv_path}")
    
    def load_data(self, dataset: str = "train") -> pd.DataFrame:
        """CSV ë°ì´í„° ë¡œë“œ"""
        if dataset == "train":
            if self.train_df is None:
                ic("ğŸ“‚ í•™ìŠµ ë°ì´í„° ë¡œë”© ì¤‘...")
                if not self.train_csv_path.exists():
                    raise FileNotFoundError(f"Train CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.train_csv_path}")
                self.train_df = pd.read_csv(self.train_csv_path)
                ic(f"âœ… {len(self.train_df)}ê°œ ìŠ¹ê° ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            return self.train_df
        else:  # test
            if self.test_df is None:
                ic("ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
                if not self.test_csv_path.exists():
                    raise FileNotFoundError(f"Test CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.test_csv_path}")
                self.test_df = pd.read_csv(self.test_csv_path)
                ic(f"âœ… {len(self.test_df)}ê°œ ìŠ¹ê° ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            return self.test_df
    
    def get_top_n_passengers_simple(self, n: int = 10, dataset: str = "train") -> List[TitanicPassengerSimple]:
        """ìƒìœ„ Nëª… ìŠ¹ê° ì¡°íšŒ (ê°„ë‹¨ ë²„ì „)"""
        try:
            df = self.load_data(dataset)
            if df is None or df.empty:
                raise ValueError(f"{dataset} ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            top_df = df.head(n)
            
            passengers = []
            for _, row in top_df.iterrows():
                # ì„±ë³„ í•œê¸€ ë³€í™˜
                sex_value = row.get('Sex', '')
                sex_kr = "ë‚¨ì„±" if sex_value == "male" else "ì—¬ì„±" if sex_value == "female" else "ë¯¸ìƒ"
                
                # ìƒì¡´ ì—¬ë¶€ í•œê¸€ ë³€í™˜ (train ë°ì´í„°ì…‹ë§Œ)
                if 'Survived' in row and pd.notna(row['Survived']):
                    survived_kr = "ìƒì¡´" if int(row['Survived']) == 1 else "ì‚¬ë§"
                else:
                    survived_kr = "ë¯¸í™•ì¸"  # test ë°ì´í„°ì…‹
                
                passenger = TitanicPassengerSimple(
                    PassengerId=int(row.get('PassengerId', 0)),
                    Name=str(row.get('Name', '')),
                    Age=float(row['Age']) if pd.notna(row.get('Age')) else None,
                    Sex=sex_kr,
                    Pclass=int(row.get('Pclass', 0)),
                    Survived=survived_kr,
                    Fare=float(row['Fare']) if pd.notna(row.get('Fare')) else None
                )
                passengers.append(passenger)
            
            ic(f"ğŸ“‹ ìƒìœ„ {n}ëª… ìŠ¹ê° ì¡°íšŒ ì™„ë£Œ")
            return passengers
        except Exception as e:
            ic(f"âŒ ìŠ¹ê° ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            raise
    
    def get_top_n_passengers(self, n: int = 10, dataset: str = "train") -> List[TitanicPassenger]:
        """ìƒìœ„ Nëª… ìŠ¹ê° ì¡°íšŒ (ì „ì²´ ì •ë³´)"""
        df = self.load_data(dataset)
        top_df = df.head(n)
        
        passengers = []
        for _, row in top_df.iterrows():
            passenger = TitanicPassenger(
                PassengerId=int(row['PassengerId']),
                Survived=int(row['Survived']) if 'Survived' in row and pd.notna(row['Survived']) else None,
                Pclass=int(row['Pclass']),
                Name=row['Name'],
                Sex=row['Sex'],
                Age=float(row['Age']) if pd.notna(row['Age']) else None,
                SibSp=int(row['SibSp']),
                Parch=int(row['Parch']),
                Ticket=row['Ticket'],
                Fare=float(row['Fare']) if pd.notna(row['Fare']) else None,
                Cabin=row['Cabin'] if pd.notna(row['Cabin']) else None,
                Embarked=row['Embarked'] if pd.notna(row['Embarked']) else None
            )
            passengers.append(passenger)
        
        ic(f"ğŸ“‹ ìƒìœ„ {n}ëª… ìŠ¹ê° ì¡°íšŒ ì™„ë£Œ (ì „ì²´ ì •ë³´)")
        return passengers
    
    def get_all_passengers(self, dataset: str = "train") -> List[TitanicPassenger]:
        """ì „ì²´ ìŠ¹ê° ì¡°íšŒ"""
        df = self.load_data(dataset)
        
        passengers = []
        for _, row in df.iterrows():
            passenger = TitanicPassenger(
                PassengerId=int(row['PassengerId']),
                Survived=int(row['Survived']) if 'Survived' in row and pd.notna(row['Survived']) else None,
                Pclass=int(row['Pclass']),
                Name=row['Name'],
                Sex=row['Sex'],
                Age=float(row['Age']) if pd.notna(row['Age']) else None,
                SibSp=int(row['SibSp']),
                Parch=int(row['Parch']),
                Ticket=row['Ticket'],
                Fare=float(row['Fare']) if pd.notna(row['Fare']) else None,
                Cabin=row['Cabin'] if pd.notna(row['Cabin']) else None,
                Embarked=row['Embarked'] if pd.notna(row['Embarked']) else None
            )
            passengers.append(passenger)
        
        ic(f"ğŸ“‹ ì „ì²´ {len(passengers)}ëª… ìŠ¹ê° ì¡°íšŒ ì™„ë£Œ")
        return passengers
    
    def get_passenger_by_id(self, passenger_id: int, dataset: str = "train") -> Optional[TitanicPassenger]:
        """ìŠ¹ê° IDë¡œ ì¡°íšŒ"""
        df = self.load_data(dataset)
        passenger_df = df[df['PassengerId'] == passenger_id]
        
        if passenger_df.empty:
            ic(f"âŒ ìŠ¹ê° {passenger_id} ì—†ìŒ")
            return None
        
        row = passenger_df.iloc[0]
        passenger = TitanicPassenger(
            PassengerId=int(row['PassengerId']),
            Survived=int(row['Survived']) if 'Survived' in row and pd.notna(row['Survived']) else None,
            Pclass=int(row['Pclass']),
            Name=row['Name'],
            Sex=row['Sex'],
            Age=float(row['Age']) if pd.notna(row['Age']) else None,
            SibSp=int(row['SibSp']),
            Parch=int(row['Parch']),
            Ticket=row['Ticket'],
            Fare=float(row['Fare']) if pd.notna(row['Fare']) else None,
            Cabin=row['Cabin'] if pd.notna(row['Cabin']) else None,
            Embarked=row['Embarked'] if pd.notna(row['Embarked']) else None
        )
        
        ic(f"âœ… ìŠ¹ê° {passenger_id} ì¡°íšŒ ì™„ë£Œ")
        return passenger
    
    #ì „ì²˜ë¦¬ ë‹¨ê³„
    def preprocess(self) -> Dict[str, Any]:
        """
        íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰
        
        Returns:
            ì „ì²˜ë¦¬ ê²°ê³¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        logs = []
        logs.append("ğŸ˜ğŸ˜ ì „ì²˜ë¦¬ ì‹œì‘")
        ic("ğŸ˜ğŸ˜ ì „ì²˜ë¦¬ ì‹œì‘")
        
        the_method = TitanicMethod()
        
        # CSV íŒŒì¼ ì½ê¸°
        df_train = the_method.read_csv("train.csv")
        df_test = the_method.read_csv("test.csv")
        
        # Survived label ì €ì¥
        self.train_labels = the_method.create_label(df_train, "Survived")
        
        # Survived ì»¬ëŸ¼ ì œê±°
        train_df = the_method.create_df(df_train, "Survived")
        test_df = the_method.create_df(df_test, "Survived")
        
        # ì „ì²˜ë¦¬ ì „ ë°ì´í„° ì €ì¥
        before_train = train_df.copy()
        before_columns = before_train.columns.tolist()
        before_sample_data = before_train.head(5).to_dict(orient="records")
        
        # TitanicDataset ê°ì²´ ìƒì„±
        this = TitanicDataset(train=train_df.copy(), test=test_df.copy())
        before_null_count = the_method.check_null(this)
        
        logs.append(f"1. Train ì˜ type: {type(this.train)}")
        logs.append(f"2. Train ì˜ column: {list(this.train.columns)}")
        logs.append(f"3. Train ì˜ ìƒìœ„ 5ê°œ í–‰:\n{this.train.head(5).to_string()}")
        logs.append(f"4. Train ì˜ null ì˜ ê°¯ìˆ˜: {the_method.check_null(TitanicDataset(train=this.train))}ê°œ")
        
        logs.append(f"1. Test ì˜ type: {type(this.test)}")
        logs.append(f"2. Test ì˜ column: {list(this.test.columns)}")
        logs.append(f"3. Test ì˜ ìƒìœ„ 5ê°œ í–‰:\n{this.test.head(5).to_string()}")
        logs.append(f"4. Test ì˜ null ì˜ ê°¯ìˆ˜: {the_method.check_null(TitanicDataset(test=this.test))}ê°œ")
        
        ic(f"1. Train ì˜ type \n {type(this.train)}")
        ic(f"2. Train ì˜ column \n {list(this.train.columns)}")
        ic(f"3. Train ì˜ ìƒìœ„ 5ê°œ í–‰\n {this.train.head(5)}")
        ic(f"4. Train ì˜ null ì˜ ê°¯ìˆ˜\n {the_method.check_null(TitanicDataset(train=this.train))}ê°œ")
        
        ic(f"1. Test ì˜ type \n {type(this.test)}")
        ic(f"2. Test ì˜ column \n {list(this.test.columns)}")
        ic(f"3. Test ì˜ ìƒìœ„ 5ê°œ í–‰\n {this.test.head(5)}")
        ic(f"4. Test ì˜ null ì˜ ê°¯ìˆ˜\n {the_method.check_null(TitanicDataset(test=this.test))}ê°œ")
        
        # ì „ì²˜ë¦¬ ì‹¤í–‰
        drop_features = ['SibSp', 'Parch', 'Cabin', 'Ticket']
        this = the_method.drop_feature(this, *drop_features)
        this = the_method.pclass_ordinal(this)
        this = the_method.fare_ordinal(this)
        this = the_method.embarked_ordinal(this)
        this = the_method.gender_nominal(this)
        this = the_method.age_ratio(this)
        this = the_method.title_nominal(this)
        drop_name = ['Name']
        this = the_method.drop_feature(this, *drop_name)
        
        logs.append("ğŸ˜ğŸ˜ ì „ì²˜ë¦¬ ì™„ë£Œ")
        logs.append(f"1. Train ì˜ type: {type(this.train)}")
        logs.append(f"2. Train ì˜ column: {list(this.train.columns)}")
        logs.append(f"3. Train ì˜ ìƒìœ„ 5ê°œ í–‰:\n{this.train.head(5).to_string()}")
        logs.append(f"4. Train ì˜ null ì˜ ê°¯ìˆ˜: {the_method.check_null(TitanicDataset(train=this.train))}ê°œ")
        
        logs.append(f"1. Test ì˜ type: {type(this.test)}")
        logs.append(f"2. Test ì˜ column: {list(this.test.columns)}")
        logs.append(f"3. Test ì˜ ìƒìœ„ 5ê°œ í–‰:\n{this.test.head(5).to_string()}")
        logs.append(f"4. Test ì˜ null ì˜ ê°¯ìˆ˜: {the_method.check_null(TitanicDataset(test=this.test))}ê°œ")
        
        ic("ğŸ˜ğŸ˜ ì „ì²˜ë¦¬ ì™„ë£Œ")
        ic(f"1. Train ì˜ type \n {type(this.train)}")
        ic(f"2. Train ì˜ column \n {list(this.train.columns)}")
        ic(f"3. Train ì˜ ìƒìœ„ 5ê°œ í–‰\n {this.train.head(5)}")
        ic(f"4. Train ì˜ null ì˜ ê°¯ìˆ˜\n {the_method.check_null(TitanicDataset(train=this.train))}ê°œ")
        
        ic(f"1. Test ì˜ type \n {type(this.test)}")
        ic(f"2. Test ì˜ column \n {list(this.test.columns)}")
        ic(f"3. Test ì˜ ìƒìœ„ 5ê°œ í–‰\n {this.test.head(5)}")
        ic(f"4. Test ì˜ null ì˜ ê°¯ìˆ˜\n {the_method.check_null(TitanicDataset(test=this.test))}ê°œ")
        
        # ì „ì²˜ë¦¬ ê²°ê³¼ ì •ë³´ ë°˜í™˜ (í”„ë¡ íŠ¸ì—”ë“œê°€ logs ë°°ì—´ì„ ê¸°ëŒ€í•¨)
        # í„°ë¯¸ë„ ë¡œê·¸ì™€ ë™ì¼í•˜ê²Œ ëª¨ë“  ê°’ì„ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        sample_df_train = this.train.head(5).copy()
        for col in sample_df_train.columns:
            if pd.api.types.is_numeric_dtype(sample_df_train[col]):
                sample_df_train[col] = sample_df_train[col].fillna(0).astype(int)
        
        sample_df_test = this.test.head(5).copy()
        for col in sample_df_test.columns:
            if pd.api.types.is_numeric_dtype(sample_df_test[col]):
                sample_df_test[col] = sample_df_test[col].fillna(0).astype(int)
        
        sample_data_train = sample_df_train.to_dict(orient="records")
        sample_data_test = sample_df_test.to_dict(orient="records")
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ (ëª¨ë¸ë§/í•™ìŠµ/í‰ê°€ì—ì„œ ì‚¬ìš©)
        self.processed_dataset = this
        
        return {
            "logs": logs,
            "status": "success",
            "train": {
                "rows": len(this.train),
                "columns": this.train.columns.tolist(),
                "column_count": len(this.train.columns),
                "null_count": int(the_method.check_null(TitanicDataset(train=this.train))),
                "sample_data": sample_data_train
            },
            "test": {
                "rows": len(this.test),
                "columns": this.test.columns.tolist(),
                "column_count": len(this.test.columns),
                "null_count": int(the_method.check_null(TitanicDataset(test=this.test))),
                "sample_data": sample_data_test
            },
            "before": {
                "columns": before_columns,
                "column_count": len(before_columns),
                "null_count": before_null_count,
                "sample_data": before_sample_data
            }
        }

    def modeling(self) -> Dict[str, Any]:
        """ëª¨ë¸ë§ ë‹¨ê³„ - ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ ëª¨ë¸ ì´ˆê¸°í™”"""
        logs = []
        logs.append("ğŸ˜ğŸ˜ ëª¨ë¸ë§ ì‹œì‘")
        ic("ğŸ˜ğŸ˜ ëª¨ë¸ë§ ì‹œì‘")
        
        if self.processed_dataset is None or self.train_labels is None:
            logs.append("âŒ ì˜¤ë¥˜: ì „ì²˜ë¦¬ê°€ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            return {
                "logs": logs,
                "status": "error",
                "message": "ì „ì²˜ë¦¬ê°€ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. preprocess()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            }
        
        # ëª¨ë¸ ì´ˆê¸°í™” (ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëœë¤ í¬ë ˆìŠ¤íŠ¸ë§Œ ì‚¬ìš©)
        self.models = {
            "ëœë¤ í¬ë ˆìŠ¤íŠ¸": RandomForestClassifier(random_state=42, n_estimators=100)
        }
        
        logs.append(f"âœ… {len(self.models)}ê°œ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        logs.append(f"ì´ˆê¸°í™”ëœ ëª¨ë¸: ëœë¤ í¬ë ˆìŠ¤íŠ¸ (ìµœê³  ì„±ëŠ¥ ëª¨ë¸)")
        
        # ëª¨ë¸ë³„ ìƒì„¸ ì •ë³´
        model_info = []
        for model_name, model in self.models.items():
            model_params = {}
            if hasattr(model, 'get_params'):
                params = model.get_params()
                # ì£¼ìš” íŒŒë¼ë¯¸í„°ë§Œ ì„ íƒ
                key_params = {k: v for k, v in params.items() if k in ['random_state', 'n_estimators']}
                model_params = key_params
            model_info.append({
                "name": model_name,
                "type": type(model).__name__,
                "parameters": model_params
            })
            logs.append(f"  - {model_name} ({type(model).__name__}): {model_params}")
        
        logs.append("ğŸ˜ğŸ˜ ëª¨ë¸ë§ ì™„ë£Œ")
        ic(f"âœ… {len(self.models)}ê°œ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {list(self.models.keys())}")
        ic("ğŸ˜ğŸ˜ ëª¨ë¸ë§ ì™„ë£Œ")
        
        
        return {
            "logs": logs,
            "status": "success",
            "message": f"{len(self.models)}ê°œ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "models": list(self.models.keys()),
            "model_count": len(self.models),
            "model_info": model_info
        }

    def learning(self) -> Dict[str, Any]:
        """í•™ìŠµ ë‹¨ê³„ - ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ"""
        logs = []
        logs.append("ğŸ˜ğŸ˜ í•™ìŠµ ì‹œì‘")
        ic("ğŸ˜ğŸ˜ í•™ìŠµ ì‹œì‘")
        
        if self.processed_dataset is None or self.train_labels is None:
            logs.append("âŒ ì˜¤ë¥˜: ì „ì²˜ë¦¬ê°€ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            return {
                "logs": logs,
                "status": "error",
                "message": "ì „ì²˜ë¦¬ê°€ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. preprocess()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            }
        
        if not self.models:
            logs.append("âŒ ì˜¤ë¥˜: ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {
                "logs": logs,
                "status": "error",
                "message": "ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. modeling()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            }
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì¤€ë¹„
        X = self.processed_dataset.train
        y = self.train_labels["Survived"]
        
        logs.append(f"ì „ì²˜ë¦¬ëœ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        logs.append(f"  - ì…ë ¥ ë°ì´í„°(X) í¬ê¸°: {X.shape}")
        logs.append(f"  - íƒ€ê²Ÿ ë°ì´í„°(y) í¬ê¸°: {y.shape}")
        
        # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        logs.append(f"í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í•  ì™„ë£Œ")
        logs.append(f"  - í•™ìŠµ ë°ì´í„°: {len(self.X_train)}ê°œ ({len(self.X_train)/len(X)*100:.1f}%)")
        logs.append(f"  - ê²€ì¦ ë°ì´í„°: {len(self.X_test)}ê°œ ({len(self.X_test)/len(X)*100:.1f}%)")
        ic(f"í•™ìŠµ ë°ì´í„°: {len(self.X_train)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(self.X_test)}ê°œ")
        
        # ëª¨ë¸ í•™ìŠµ (ëœë¤ í¬ë ˆìŠ¤íŠ¸)
        trained_models = {}
        logs.append("ëª¨ë¸ í•™ìŠµ ì‹œì‘:")
        for model_name, model in self.models.items():
            logs.append(f"  {model_name} í•™ìŠµ ì¤‘...")
            ic(f"ğŸ“š {model_name} í•™ìŠµ ì¤‘...")
            model.fit(self.X_train, self.y_train)
            trained_models[model_name] = "í•™ìŠµ ì™„ë£Œ"
            logs.append(f"     âœ… {model_name} í•™ìŠµ ì™„ë£Œ")
            ic(f"âœ… {model_name} í•™ìŠµ ì™„ë£Œ")
        
        logs.append("ğŸ˜ğŸ˜ í•™ìŠµ ì™„ë£Œ")
        logs.append(f"ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
        ic("ğŸ˜ğŸ˜ í•™ìŠµ ì™„ë£Œ")
        
        return {
            "logs": logs,
            "status": "success",
            "message": f"{len(trained_models)}ê°œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ",
            "trained_models": list(trained_models.keys()),
            "train_size": len(self.X_train),
            "test_size": len(self.X_test),
            "model_count": len(trained_models)
        }
    
    #í›„ì²˜ë¦¬ ë‹¨ê³„(ì¶”ë¡  ë‹¨ê³„) 
    def evaluate(self) -> Dict[str, Any]:
        """í‰ê°€ ë‹¨ê³„ - í•™ìŠµëœ ëª¨ë¸ë“¤ì˜ ê²€ì¦ ì •í™•ë„ í‰ê°€"""
        logs = []
        logs.append("ğŸ˜ğŸ˜ í‰ê°€ ì‹œì‘")
        ic("ğŸ˜ğŸ˜ í‰ê°€ ì‹œì‘")
        
        if not self.models:
            logs.append("âŒ ì˜¤ë¥˜: ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {
                "logs": logs,
                "status": "error",
                "message": "ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. modeling()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            }
        
        if self.X_test is None or self.y_test is None:
            logs.append("âŒ ì˜¤ë¥˜: í•™ìŠµì´ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            return {
                "logs": logs,
                "status": "error",
                "message": "í•™ìŠµì´ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. learning()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            }
        
        logs.append(f"ê²€ì¦ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        logs.append(f"  - ê²€ì¦ ë°ì´í„° í¬ê¸°: {len(self.X_test)}ê°œ")
        logs.append("ëª¨ë¸ í‰ê°€ ì‹œì‘:")
        
        # ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í‰ê°€
        results = {}
        for model_name, model in self.models.items():
            logs.append(f"  {model_name} í‰ê°€ ì¤‘...")
            y_pred = model.predict(self.X_test)
            accuracy = accuracy_score(self.y_test, y_pred)
            results[model_name] = round(accuracy * 100, 2)
            logs.append(f"     âœ… {model_name} í™œìš©í•œ ê²€ì¦ ì •í™•ë„: {accuracy * 100:.2f}%")
            ic(f'{model_name} í™œìš©í•œ ê²€ì¦ ì •í™•ë„: {accuracy * 100:.2f}%')
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ (ëœë¤ í¬ë ˆìŠ¤íŠ¸)
        best_model = list(results.keys())[0] if results else None
        best_accuracy = list(results.values())[0] if results else None
        
        logs.append("ğŸ˜ğŸ˜ í‰ê°€ ì™„ë£Œ")
        logs.append("=" * 50)
        logs.append("í‰ê°€ ê²°ê³¼:")
        if best_model and best_accuracy:
            logs.append(f"  - ëª¨ë¸: {best_model}")
            logs.append(f"  - ê²€ì¦ ì •í™•ë„: {best_accuracy}%")
        logs.append("=" * 50)
        
        ic("ğŸ˜ğŸ˜ í‰ê°€ ì™„ë£Œ")
        
        return {
            "logs": logs,
            "status": "success",
            "message": "ëª¨ë¸ í‰ê°€ ì™„ë£Œ",
            "results": results,
            "best_model": best_model,
            "best_accuracy": best_accuracy,
            "model_count": len(results)
        }

    def submit(self) -> Dict[str, Any]:
        """ì œì¶œ ë‹¨ê³„ - ìºê¸€ ì œì¶œìš© submission.csv íŒŒì¼ ìƒì„±"""
        logs = []
        logs.append("ğŸ˜ğŸ˜ ì œì¶œ ì‹œì‘")
        ic("ğŸ˜ğŸ˜ ì œì¶œ ì‹œì‘")
        
        if not self.models:
            logs.append("âŒ ì˜¤ë¥˜: ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {
                "logs": logs,
                "status": "error",
                "message": "ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. modeling()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            }
        
        if self.processed_dataset is None:
            logs.append("âŒ ì˜¤ë¥˜: ì „ì²˜ë¦¬ê°€ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            return {
                "logs": logs,
                "status": "error",
                "message": "ì „ì²˜ë¦¬ê°€ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. preprocess()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            }
        
        # í•™ìŠµëœ ëª¨ë¸ í™•ì¸
        if not hasattr(list(self.models.values())[0], 'predict'):
            logs.append("âŒ ì˜¤ë¥˜: ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {
                "logs": logs,
                "status": "error",
                "message": "ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. learning()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
            }
        
        # test.csv ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰
        X_test_submit = self.processed_dataset.test
        model = list(self.models.values())[0]  # ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸
        
        logs.append("í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...")
        ic("í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘...")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = model.predict(X_test_submit)
        
        # PassengerId ê°€ì ¸ì˜¤ê¸°
        the_method = TitanicMethod()
        df_test_original = the_method.read_csv("test.csv")
        passenger_ids = df_test_original["PassengerId"].values
        
        logs.append(f"ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ")
        logs.append(f"PassengerId ë²”ìœ„: {passenger_ids.min()} ~ {passenger_ids.max()}")
        
        # submission.csv ìƒì„±
        submission_df = pd.DataFrame({
            'PassengerId': passenger_ids,
            'Survived': predictions.astype(int)
        })
        
        # models í´ë”ì— ì €ì¥
        # __file__ì€ titanic_service.pyì˜ ê²½ë¡œì´ë¯€ë¡œ, parent.parentëŠ” app/ ë””ë ‰í† ë¦¬
        models_dir = Path(__file__).parent.parent / "models"
        models_dir.mkdir(exist_ok=True, parents=True)
        submission_path = models_dir / "submission.csv"
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ì—¬ ë¡œê·¸ì— í‘œì‹œ
        abs_submission_path = submission_path.resolve()
        
        logs.append(f"ì €ì¥ ê²½ë¡œ: {abs_submission_path}")
        logs.append(f"ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸: {models_dir.exists()}")
        logs.append(f"ë””ë ‰í† ë¦¬ ì ˆëŒ€ ê²½ë¡œ: {models_dir.resolve()}")
        
        # CSV íŒŒì¼ ì €ì¥
        try:
            submission_df.to_csv(submission_path, index=False)
            logs.append(f"íŒŒì¼ ì €ì¥ ì‹œë„ ì™„ë£Œ")
        except Exception as e:
            logs.append(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            raise
        
        # íŒŒì¼ ìƒì„± í™•ì¸
        if submission_path.exists():
            file_size = submission_path.stat().st_size
            logs.append(f"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {abs_submission_path}")
            logs.append(f"íŒŒì¼ í¬ê¸°: {file_size} bytes")
            logs.append(f"ì´ ì˜ˆì¸¡ ìˆ˜: {len(submission_df)}ê°œ")
            logs.append(f"ìƒì¡´ ì˜ˆì¸¡: {predictions.sum()}ëª… ({predictions.sum()/len(predictions)*100:.2f}%)")
            logs.append(f"ì‚¬ë§ ì˜ˆì¸¡: {(predictions == 0).sum()}ëª… ({(predictions == 0).sum()/len(predictions)*100:.2f}%)")
            logs.append("ğŸ˜ğŸ˜ ì œì¶œ ì™„ë£Œ")
            
            ic(f"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {abs_submission_path}")
            ic(f"íŒŒì¼ í¬ê¸°: {file_size} bytes")
            ic("ğŸ˜ğŸ˜ ì œì¶œ ì™„ë£Œ")
        else:
            logs.append(f"âŒ ì˜¤ë¥˜: íŒŒì¼ ìƒì„± ì‹¤íŒ¨ - {abs_submission_path}")
            ic(f"âŒ ì˜¤ë¥˜: íŒŒì¼ ìƒì„± ì‹¤íŒ¨ - {abs_submission_path}")
        
        return {
            "logs": logs,
            "status": "success" if submission_path.exists() else "error",
            "message": "ìºê¸€ ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤." if submission_path.exists() else "íŒŒì¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
            "file_path": str(abs_submission_path),
            "file_name": "submission.csv",
            "file_exists": submission_path.exists(),
            "total_predictions": len(submission_df),
            "survived_count": int(predictions.sum()),
            "died_count": int((predictions == 0).sum()),
            "sample_predictions": submission_df.head(10).to_dict(orient="records")
        }
    
    # ========================================================================
    # Routerì—ì„œ í˜¸ì¶œí•˜ëŠ” ì¶”ê°€ ë©”ì„œë“œë“¤ (í–¥í›„ êµ¬í˜„ ì˜ˆì •)
    # ========================================================================
    
    def filter_by_survived(self, survived: bool, dataset: str = "train") -> List[TitanicPassenger]:
        """ìƒì¡´ ì—¬ë¶€ë¡œ í•„í„°ë§"""
        df = self.load_data(dataset)
        if 'Survived' not in df.columns:
            return []
        filtered_df = df[df['Survived'] == (1 if survived else 0)]
        
        passengers = []
        for _, row in filtered_df.iterrows():
            passenger = TitanicPassenger(
                PassengerId=int(row['PassengerId']),
                Survived=int(row['Survived']) if pd.notna(row['Survived']) else None,
                Pclass=int(row['Pclass']),
                Name=row['Name'],
                Sex=row['Sex'],
                Age=float(row['Age']) if pd.notna(row['Age']) else None,
                SibSp=int(row['SibSp']),
                Parch=int(row['Parch']),
                Ticket=row['Ticket'],
                Fare=float(row['Fare']) if pd.notna(row['Fare']) else None,
                Cabin=row['Cabin'] if pd.notna(row['Cabin']) else None,
                Embarked=row['Embarked'] if pd.notna(row['Embarked']) else None
            )
            passengers.append(passenger)
        return passengers
    
    def filter_by_pclass(self, pclass: int, dataset: str = "train") -> List[TitanicPassenger]:
        """ê°ì‹¤ ë“±ê¸‰ìœ¼ë¡œ í•„í„°ë§"""
        df = self.load_data(dataset)
        filtered_df = df[df['Pclass'] == pclass]
        
        passengers = []
        for _, row in filtered_df.iterrows():
            passenger = TitanicPassenger(
                PassengerId=int(row['PassengerId']),
                Survived=int(row['Survived']) if 'Survived' in row and pd.notna(row['Survived']) else None,
                Pclass=int(row['Pclass']),
                Name=row['Name'],
                Sex=row['Sex'],
                Age=float(row['Age']) if pd.notna(row['Age']) else None,
                SibSp=int(row['SibSp']),
                Parch=int(row['Parch']),
                Ticket=row['Ticket'],
                Fare=float(row['Fare']) if pd.notna(row['Fare']) else None,
                Cabin=row['Cabin'] if pd.notna(row['Cabin']) else None,
                Embarked=row['Embarked'] if pd.notna(row['Embarked']) else None
            )
            passengers.append(passenger)
        return passengers
    
    def filter_by_sex(self, sex: str, dataset: str = "train") -> List[TitanicPassenger]:
        """ì„±ë³„ë¡œ í•„í„°ë§"""
        df = self.load_data(dataset)
        filtered_df = df[df['Sex'] == sex]
        
        passengers = []
        for _, row in filtered_df.iterrows():
            passenger = TitanicPassenger(
                PassengerId=int(row['PassengerId']),
                Survived=int(row['Survived']) if 'Survived' in row and pd.notna(row['Survived']) else None,
                Pclass=int(row['Pclass']),
                Name=row['Name'],
                Sex=row['Sex'],
                Age=float(row['Age']) if pd.notna(row['Age']) else None,
                SibSp=int(row['SibSp']),
                Parch=int(row['Parch']),
                Ticket=row['Ticket'],
                Fare=float(row['Fare']) if pd.notna(row['Fare']) else None,
                Cabin=row['Cabin'] if pd.notna(row['Cabin']) else None,
                Embarked=row['Embarked'] if pd.notna(row['Embarked']) else None
            )
            passengers.append(passenger)
        return passengers
    
    def calculate_survival_rate(self, dataset: str = "train") -> Dict[str, Any]:
        """ìƒì¡´ìœ¨ í†µê³„ ê³„ì‚°"""
        df = self.load_data(dataset)
        if 'Survived' not in df.columns:
            return {"error": "Survived ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤"}
        
        total = len(df)
        survived = df['Survived'].sum()
        died = total - survived
        survival_rate = (survived / total * 100) if total > 0 else 0
        
        return {
            "total": total,
            "survived": int(survived),
            "died": int(died),
            "survival_rate": round(survival_rate, 2)
        }
    
    def calculate_age_statistics(self, dataset: str = "train") -> Dict[str, Any]:
        """ë‚˜ì´ í†µê³„ ê³„ì‚°"""
        df = self.load_data(dataset)
        age_series = df['Age'].dropna()
        
        if len(age_series) == 0:
            return {"error": "ë‚˜ì´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        return {
            "mean": round(float(age_series.mean()), 2),
            "min": round(float(age_series.min()), 2),
            "max": round(float(age_series.max()), 2),
            "median": round(float(age_series.median()), 2),
            "std": round(float(age_series.std()), 2)
        }
    
    def get_data_summary(self, dataset: str = "train") -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ ìš”ì•½ ì •ë³´"""
        df = self.load_data(dataset)
        return {
            "shape": list(df.shape),
            "columns": list(df.columns),
            "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
            "null_counts": df.isnull().sum().to_dict(),
            "describe": df.describe().to_dict()
        }
    
    def calculate_correlation_matrix(self, dataset: str = "train") -> Dict[str, Any]:
        """ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°"""
        df = self.load_data(dataset)
        numeric_df = df.select_dtypes(include=[np.number])
        correlation = numeric_df.corr()
        return {
            "correlation_matrix": correlation.to_dict(),
            "columns": list(correlation.columns)
        }
    
    def preprocess_data_for_ml(self, dataset: str = "train") -> Dict[str, Any]:
        """MLì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬"""
        # TODO: í–¥í›„ êµ¬í˜„
        return {"message": "ì „ì²˜ë¦¬ ê¸°ëŠ¥ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤"}
    
    def split_train_test(self, dataset: str = "train", test_size: float = 0.2, random_state: int = 42) -> Dict[str, Any]:
        """í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• """
        # TODO: í–¥í›„ êµ¬í˜„
        return {"message": "ë°ì´í„° ë¶„í•  ê¸°ëŠ¥ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤"}
    
    def get_numpy_statistics(self, dataset: str = "train") -> Dict[str, Any]:
        """NumPyë¥¼ í™œìš©í•œ í†µê³„ ì •ë³´"""
        df = self.load_data(dataset)
        numeric_df = df.select_dtypes(include=[np.number])
        
        return {
            "mean": {col: float(np.mean(numeric_df[col].dropna())) for col in numeric_df.columns},
            "std": {col: float(np.std(numeric_df[col].dropna())) for col in numeric_df.columns},
            "min": {col: float(np.min(numeric_df[col].dropna())) for col in numeric_df.columns},
            "max": {col: float(np.max(numeric_df[col].dropna())) for col in numeric_df.columns}
        }
    
    def load_huggingface_dataset(self, dataset: str = "train") -> Any:
        """HuggingFace Datasetìœ¼ë¡œ ë¡œë“œ"""
        # TODO: í–¥í›„ êµ¬í˜„
        from datasets import Dataset
        df = self.load_data(dataset)
        return Dataset.from_pandas(df)
    
    def create_dataset_dict(self) -> Any:
        """HuggingFace DatasetDict ìƒì„±"""
        # TODO: í–¥í›„ êµ¬í˜„
        from datasets import Dataset, DatasetDict
        train_df = self.load_data("train")
        test_df = self.load_data("test")
        
        return DatasetDict({
            "train": Dataset.from_pandas(train_df),
            "test": Dataset.from_pandas(test_df)
        })